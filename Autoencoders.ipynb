{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoencoderCorr.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lNPQmwxfw3Hw",
        "89B96ifEFcS-"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRB5NP3YwTs7",
        "outputId": "935398b3-7ae4-4040-f646-6d67a0a2f592"
      },
      "source": [
        "!pip install tabulate\n",
        "!pip install StatisticalAnalysis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.9)\n",
            "Collecting StatisticalAnalysis\n",
            "  Downloading https://files.pythonhosted.org/packages/76/10/1c28b9f30784d467201ce03c26d3669a91273cc96e86473dd480319e0d0d/StatisticalAnalysis-0.0.5.tar.gz\n",
            "Building wheels for collected packages: StatisticalAnalysis\n",
            "  Building wheel for StatisticalAnalysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for StatisticalAnalysis: filename=StatisticalAnalysis-0.0.5-py2.py3-none-any.whl size=13106 sha256=5e238bfa2942327d313458686eadf2d6ae6a7c702c2afb711ce53b0908c2785f\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/25/c2/06c9fdf3fc87bad4738237bc3318b20a7971189d5399f26ef7\n",
            "Successfully built StatisticalAnalysis\n",
            "Installing collected packages: StatisticalAnalysis\n",
            "Successfully installed StatisticalAnalysis-0.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j54vhd8wle4"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79wdl8cCwqc2"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNPQmwxfw3Hw"
      },
      "source": [
        "# Autoencoder Corr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT_1KyEywsFq"
      },
      "source": [
        "corr_hc = np.load('corr_hc.npy')\n",
        "corr_schz = np.load('corr_schz.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_k-vRLjw2pJ"
      },
      "source": [
        "input_img = layers.Input(shape=(118,118,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foWFZ43Zw5yA"
      },
      "source": [
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSH0XWMAw7F5"
      },
      "source": [
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='tanh', padding='valid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71P8JUMhw8m_"
      },
      "source": [
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii2jFxzAzIBa",
        "outputId": "5ca796ab-d1cd-429b-bcf4-19248f424ae1"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 118, 118, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 118, 118, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 59, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 59, 59, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 1)         289       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 15, 15, 1)         10        \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 30, 30, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 60, 60, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 60, 60, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 120, 120, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 118, 118, 1)       289       \n",
            "=================================================================\n",
            "Total params: 19,724\n",
            "Trainable params: 19,724\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4uMHOuww-Is"
      },
      "source": [
        "X = np.append(corr_hc,corr_schz,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLoYWL4AxApg"
      },
      "source": [
        "X = np.reshape(X, (len(X), 118, 118, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMR4AhpcxCPf",
        "outputId": "b755d3d8-1ba6-4bed-d92e-b6fad0c0aa4f"
      },
      "source": [
        "autoencoder.fit(X, X,epochs=100,batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 635ms/step - loss: 0.3799\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.2872\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2672\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.2109\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.1202\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0708\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0999\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1305\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1345\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.1194\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0954\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0747\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0679\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0747\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0846\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0884\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0852\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0775\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0692\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0638\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0630\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0655\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0680\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0687\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0673\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0642\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0606\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0579\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0573\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0583\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0592\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0589\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0575\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0559\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0551\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0553\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0556\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0553\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0544\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0536\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0532\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0531\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0531\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0531\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0528\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0525\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0522\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0521\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0522\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0522\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0520\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0518\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0517\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0518\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0517\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0516\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0514\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0514\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0514\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0514\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0512\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0512\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0512\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0512\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0511\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0510\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0510\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0510\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0509\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0508\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0508\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0508\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0507\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0507\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0507\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0506\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0506\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0506\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0505\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0505\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0505\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0504\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0504\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0504\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0503\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0503\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0503\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0502\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0502\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0502\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0501\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0501\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0501\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0500\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0500\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0500\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0500\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0499\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0499\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe936328a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2GJni4yxD2t"
      },
      "source": [
        "encoder = keras.Model(autoencoder.input, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAHc8yANxdOb",
        "outputId": "411fe64d-999d-42e6-ac0e-2a5f489471c1"
      },
      "source": [
        "encoder.predict(X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 15, 15, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyo1DP03ysYI"
      },
      "source": [
        "np.save('corrAutoencoder.npy',encoder.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgzU2cUA1W1L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6igpO501fcI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iemsH8tB1hQH"
      },
      "source": [
        "# Autoencoder TS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vyEACm_1hQJ"
      },
      "source": [
        "ts_hc = np.load('ts_hc.npy')\n",
        "ts_schz = np.load('ts_schz.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D7eE4X01nF3"
      },
      "source": [
        "ts_hc /= 10\n",
        "ts_schz /= 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-UEcAWi1hQK"
      },
      "source": [
        "input_img = layers.Input(shape=(142,118,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_kactO61hQK"
      },
      "source": [
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNpky8Uj1hQK"
      },
      "source": [
        "x = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='tanh', padding='valid')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_WmCIDQ1hQK"
      },
      "source": [
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJtifISh1hQL",
        "outputId": "e615e6c3-2c3f-4f2e-81aa-72ec96b64b88"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 142, 118, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 142, 118, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 71, 59, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 71, 59, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 36, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 36, 30, 1)         289       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 18, 15, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 18, 15, 1)         10        \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 36, 30, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 36, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2 (None, 72, 60, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 72, 60, 32)        9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2 (None, 144, 120, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 142, 118, 1)       289       \n",
            "=================================================================\n",
            "Total params: 19,724\n",
            "Trainable params: 19,724\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1dR3UFF1hQM"
      },
      "source": [
        "X = np.append(ts_hc,ts_schz,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAOaeWDf1hQM"
      },
      "source": [
        "X = np.reshape(X, (len(X), 142, 118, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8fU9-C1hQN",
        "outputId": "c887115f-d87f-469b-82ab-1b62f1fbdd20"
      },
      "source": [
        "autoencoder.fit(X, X,epochs=100,batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0100\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0100\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0100\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0100\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0100\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0100\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0100\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0100\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0099\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0099\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0099\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0098\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0098\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0097\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0096\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0094\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0093\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0092\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0090\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0089\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0088\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0088\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0087\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0087\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0087\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0086\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0085\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0085\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0084\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0084\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0083\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0083\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0082\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0082\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0082\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0082\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0082\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0081\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0081\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0081\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0081\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0081\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0080\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0080\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0080\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0080\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0080\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0079\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0079\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0079\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0079\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0079\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0078\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0078\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0078\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0078\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0078\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0077\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0077\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0077\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0077\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0077\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0077\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0078\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0077\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0076\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0077\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0076\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0076\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0076\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0076\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0076\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0076\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0076\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0076\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0076\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0075\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0075\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0075\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0075\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0075\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0075\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0075\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0075\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0075\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0075\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0075\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0075\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0075\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0075\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0075\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0075\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0075\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0075\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0074\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0074\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0074\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0074\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0074\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8567a15d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzmpmohq1hQN"
      },
      "source": [
        "encoder = keras.Model(autoencoder.input, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZQKcOtR1hQN",
        "outputId": "a839e504-a436-4f50-c02d-4f7b1db19f1c"
      },
      "source": [
        "encoder.predict(X).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 18, 15, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs-1cYBX1hQO"
      },
      "source": [
        "np.save('tsAutoencoder.npy',encoder.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTNbjL0u1hQP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFB9kzPxBEJR"
      },
      "source": [
        "## Denoising autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OHCgDoTA7uy"
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "class ConvAutoencoder:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, filters=(32, 64), latentDim=16):\n",
        "\t\t# initialize the input shape to be \"channels last\" along with\n",
        "\t\t# the channels dimension itself\n",
        "\t\t# channels dimension itself\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\t\t# define the input to the encoder\n",
        "\t\tinputs = Input(shape=inputShape)\n",
        "\t\tx = inputs\n",
        "\t\t# loop over the number of filters\n",
        "\t\tfor f in filters:\n",
        "\t\t\t# apply a CONV => RELU => BN operation\n",
        "\t\t\tx = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
        "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\t# flatten the network and then construct our latent vector\n",
        "\t\tvolumeSize = K.int_shape(x)\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tlatent = Dense(latentDim)(x)\n",
        "\t\t# build the encoder model\n",
        "\t\tencoder = Model(inputs, latent, name=\"encoder\")\n",
        "\t\t# start building the decoder model which will accept the\n",
        "\t\t# output of the encoder as its inputs\n",
        "\t\tlatentInputs = Input(shape=(latentDim,))\n",
        "\t\tx = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
        "\t\tx = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
        "\t\t# loop over our number of filters again, but this time in\n",
        "\t\t# reverse order\n",
        "\t\tfor f in filters[::-1]:\n",
        "\t\t\t# apply a CONV_TRANSPOSE => RELU => BN operation\n",
        "\t\t\tx = Conv2DTranspose(f, (3, 3), strides=2,\n",
        "\t\t\t\tpadding=\"same\")(x)\n",
        "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\t# apply a single CONV_TRANSPOSE layer used to recover the\n",
        "\t\t# original depth of the image x = \n",
        "\t\tx = Conv2D(1, (3, 3),  padding='valid')(x) #Conv2DTranspose(depth, (3, 3), padding=\"same\")(x) \n",
        "    \n",
        "\t\toutputs = Activation(\"tanh\")(x)\n",
        "\t\t# build the decoder model\n",
        "\t\tdecoder = Model(latentInputs, outputs, name=\"decoder\")\n",
        "\t\t# our autoencoder is the encoder + decoder\n",
        "\t\tautoencoder = Model(inputs, decoder(encoder(inputs)),\n",
        "\t\t\tname=\"autoencoder\")\n",
        "\t\t# return a 3-tuple of the encoder, decoder, and autoencoder\n",
        "\t\treturn (encoder, decoder, autoencoder)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_QcnESMBJmM"
      },
      "source": [
        "EPOCHS = 25\n",
        "BS = 32\n",
        "# load the MNIST dataset\n",
        "corr_hc = np.load('corr_hc.npy')\n",
        "corr_schz = np.load('corr_schz.npy')\n",
        "X = np.append(corr_hc,corr_schz,axis=0)\n",
        "X = np.reshape(X, (len(X), 118, 118, 1))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mYT9XVgBxQU",
        "outputId": "97b27951-8ffc-4d73-f7d2-9025f36eb62a"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(118, 118, 1)\n",
        "opt = Adam(lr=1e-3)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "\tX, X,\n",
        "\tvalidation_data=(X, X),\n",
        "\tepochs=EPOCHS,\n",
        "\tbatch_size=BS)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 31s 152ms/step - loss: 0.7382 - val_loss: 0.2697\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.3657 - val_loss: 0.2388\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.2369 - val_loss: 0.2015\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.1815 - val_loss: 0.1733\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.1460 - val_loss: 0.1426\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.1180 - val_loss: 0.1137\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0984 - val_loss: 0.0960\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0858 - val_loss: 0.0821\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0777 - val_loss: 0.0758\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0713 - val_loss: 0.0733\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0682 - val_loss: 0.0730\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0630 - val_loss: 0.0725\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0560 - val_loss: 0.0720\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0522 - val_loss: 0.0718\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0483 - val_loss: 0.0721\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0447 - val_loss: 0.0735\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.0431 - val_loss: 0.0758\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0415 - val_loss: 0.0737\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.0399 - val_loss: 0.0776\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0383 - val_loss: 0.0812\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0369 - val_loss: 0.0818\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0813\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0352 - val_loss: 0.0832\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0335 - val_loss: 0.0825\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0316 - val_loss: 0.0830\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2cxmkhAB04n",
        "outputId": "3baf6c37-3c79-4285-b9b6-76ec6c9e6ecc"
      },
      "source": [
        "encoder"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f6983ff1690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdyv19LfD2u8"
      },
      "source": [
        "np.save('corrAutoencoderDenoise.npy',encoder.predict(X))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99nm8w5rECja"
      },
      "source": [
        "EPOCHS = 25\n",
        "BS = 32\n",
        "# load the MNIST dataset\n",
        "ts_hc = np.load('ts_hc.npy')\n",
        "ts_schz = np.load('ts_schz.npy')\n",
        "X = np.append(ts_hc,ts_schz,axis=0)\n",
        "X = np.reshape(X, (len(X), 142, 118, 1))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImB-C4ltELo5",
        "outputId": "b72fea63-5480-4714-ffb7-526eb16aaa76"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "(encoder, decoder, autoencoder) = ConvAutoencoder.build(118, 142, 1)\n",
        "opt = Adam(lr=1e-3)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
        "# train the convolutional autoencoder\n",
        "H = autoencoder.fit(\n",
        "\tX, X,\n",
        "\tvalidation_data=(X, X),\n",
        "\tepochs=EPOCHS,\n",
        "\tbatch_size=BS)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 196ms/step - loss: 1.4630 - val_loss: 0.9994\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1.1290 - val_loss: 0.9965\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.9553 - val_loss: 0.9895\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.8392 - val_loss: 0.9825\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.7759 - val_loss: 0.9735\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.7234 - val_loss: 0.9608\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.6715 - val_loss: 0.9556\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.6415 - val_loss: 0.9456\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.6034 - val_loss: 0.9307\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.5657 - val_loss: 0.9240\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.5291 - val_loss: 0.9061\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.4957 - val_loss: 0.8987\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.4553 - val_loss: 0.8772\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.4302 - val_loss: 0.8651\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.4153 - val_loss: 0.8544\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3920 - val_loss: 0.8292\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3740 - val_loss: 0.8154\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3565 - val_loss: 0.8136\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3404 - val_loss: 0.7983\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3291 - val_loss: 0.7782\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.3196 - val_loss: 0.7529\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.3122 - val_loss: 0.7427\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.3088 - val_loss: 0.7174\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.2981 - val_loss: 0.7095\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.2884 - val_loss: 0.7020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkOoOkkBEQd7"
      },
      "source": [
        "np.save('tsAutoencoderDenoise.npy',encoder.predict(X))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89B96ifEFcS-"
      },
      "source": [
        "# Sparse Autoencoder Corr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbQtk7AAFxds"
      },
      "source": [
        "corr_hc = np.load('corr_hc.npy')\n",
        "corr_schz = np.load('corr_schz.npy')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAvBAVR9Fxdt"
      },
      "source": [
        "input_img = layers.Input(shape=(118*118,))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJn-oGAdFxdt"
      },
      "source": [
        "from keras import regularizers\n",
        "encoding_dim = 32\n",
        "# Add a Dense layer with a L1 activity regularizer\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = layers.Dense(118*118, activation='tanh')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8O2ja27Fxdu"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx1eVn4qFxdv",
        "outputId": "7f316250-4dc6-4c2d-8a30-0b188ee421d2"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 13924)]           0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                445600    \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 13924)             459492    \n",
            "=================================================================\n",
            "Total params: 905,092\n",
            "Trainable params: 905,092\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4jRvLZ_Fxdw"
      },
      "source": [
        "X = np.append(corr_hc,corr_schz,axis=0)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svPAfQrCFxdx"
      },
      "source": [
        "X = np.reshape(X, (len(X), 118*118, 1))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0NfGooFFxdx",
        "outputId": "b56c3622-e27c-4967-c607-292a455b6b49"
      },
      "source": [
        "autoencoder.fit(X, X,epochs=100,batch_size=128)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 391ms/step - loss: 0.3120\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3087\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3028\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2946\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2754\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2524\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2321\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2127\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1912\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1686\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1472\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1288\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1137\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1004\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0887\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0792\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0721\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0663\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0612\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0570\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0542\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0523\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0504\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0488\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0477\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0470\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0462\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0452\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0446\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0442\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0436\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0431\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0428\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0425\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0420\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0418\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0417\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0414\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0412\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0411\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0408\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0407\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0406\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0404\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0403\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0402\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0401\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0400\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0399\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0398\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0398\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0397\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0396\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0396\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0395\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0394\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0394\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0393\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0393\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0393\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0392\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0392\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0392\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0391\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0391\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0391\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0390\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0390\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0390\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0390\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0389\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0389\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0389\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0389\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0389\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0388\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0388\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0388\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0388\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0388\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0388\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0387\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0387\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0387\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0387\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0387\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0387\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0387\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0386\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0386\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0386\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0386\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0386\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0386\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0386\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0386\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0386\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0385\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0385\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f699a7990d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViSF3G7tFxdz"
      },
      "source": [
        "encoder = keras.Model(autoencoder.input, encoded)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb9t8L8kFxdz",
        "outputId": "0c10ab9a-2618-4caa-ad41-e5c8975c66fb"
      },
      "source": [
        "encoder.predict(X).shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQWh7OXFxdz"
      },
      "source": [
        "np.save('corrAutoencoderSparse.npy',encoder.predict(X))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rct0ql9OFxdz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCq2bLTAFxd0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQToeEcoEZbU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hj-1jA2H9x3"
      },
      "source": [
        "# Sparse Autoencoder ts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odEyAORQH9x5"
      },
      "source": [
        "ts_hc = np.load('ts_hc.npy')\n",
        "ts_schz = np.load('ts_schz.npy')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9zm5RmsIFj8",
        "outputId": "821d30b4-32f0-42e0-85c7-3a7bbbae01e3"
      },
      "source": [
        "ts_hc.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 142, 118)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07LMWFIKH9x5"
      },
      "source": [
        "input_img = layers.Input(shape=(142*118,))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqEW1Sq0H9x7"
      },
      "source": [
        "from keras import regularizers\n",
        "encoding_dim = 32\n",
        "# Add a Dense layer with a L1 activity regularizer\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = layers.Dense(142*118, activation='tanh')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjIM9bScH9x7"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfYijVH0H9x8",
        "outputId": "03df8cba-a30c-4e0c-c5e4-eb25064aa887"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        [(None, 16756)]           0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 32)                536224    \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 16756)             552948    \n",
            "=================================================================\n",
            "Total params: 1,089,172\n",
            "Trainable params: 1,089,172\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU4FkQx6H9x9"
      },
      "source": [
        "X = np.append(ts_hc,ts_schz,axis=0)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtoWaaA2H9x9"
      },
      "source": [
        "X = np.reshape(X, (len(X), 142*118, 1))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F04AvqP0H9x-",
        "outputId": "96e02f34-e905-4bd2-de2d-ad9dd2e8ff5c"
      },
      "source": [
        "autoencoder.fit(X, X,epochs=100,batch_size=128)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 389ms/step - loss: 1.0059\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0018\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9995\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9970\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9930\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9864\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9768\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9644\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9492\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9317\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.9126\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8922\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8706\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8486\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8266\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8050\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7841\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7641\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7452\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7276\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7110\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6956\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6812\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6676\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6549\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6430\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6319\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6214\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6115\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6023\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5937\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5857\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5783\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5713\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5648\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5588\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5531\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5476\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5425\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5378\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5290\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5250\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5212\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5177\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5143\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5111\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5081\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5052\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5024\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4998\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4972\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4949\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4926\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4904\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4883\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4863\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4843\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4825\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4807\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4790\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4774\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4757\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4742\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4728\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4713\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4699\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4686\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4673\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4661\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4649\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4637\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4626\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4615\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4604\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4594\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4584\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4574\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4565\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4556\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4547\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4538\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4530\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4522\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4514\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4507\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4499\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4492\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4485\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4478\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4471\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4465\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4458\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4452\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4446\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4440\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4435\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4429\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4424\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f69170b7650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIpFPs3oH9x_"
      },
      "source": [
        "encoder = keras.Model(autoencoder.input, encoded)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcBatrm3H9x_",
        "outputId": "a7c84550-8f98-4616-d27f-da3e402ccd13"
      },
      "source": [
        "encoder.predict(X).shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce_OXKINH9yB"
      },
      "source": [
        "np.save('tsAutoencoderSparse.npy',encoder.predict(X))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipa5L5sRH9yB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs8UB6AyH9yB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F36FNcFBH9yB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}